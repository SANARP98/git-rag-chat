# Git RAG Chat - Local Repository Code Analysis

A Docker-based RAG (Retrieval-Augmented Generation) chatbot system that tracks Git changes (committed and uncommitted) and enables natural language querying of code repositories using ChromaDB for vector storage.

## Features

- **Multi-Repository Support**: Track multiple Git repositories with persistent vector indexes
- **Real-Time Change Tracking**: Monitor both committed and uncommitted changes
- **Intelligent Code Parsing**: AST-based semantic chunking using tree-sitter
- **LLM Integration**: Codex CLI with ChatGPT Enterprise (GPT-4) support
- **Directory Picker UI**: Gradio web interface for easy repository selection
- **Fully Containerized**: Docker Compose deployment for easy setup

## Development Status

### âœ… Phase 1, 2 & 3: Core Pipeline Complete

**Phase 1** (Foundation):

- âœ… Project structure created
- âœ… Docker Compose configuration
- âœ… SQLite metadata database
- âœ… Configuration management
- âœ… FastAPI application skeleton with API routes

**Phase 2** (Git & Parsing):

- âœ… GitPython integration for commit history
- âœ… tree-sitter code parser (Python, JavaScript, TypeScript)
- âœ… Chunking strategies (AST-based + fixed-size)
- âœ… File tracking and validation

**Phase 3** (Embedding & Vector Store):

- âœ… ChromaDB integration with collection management
- âœ… sentence-transformers embedding generation
- âœ… Repository indexing orchestration
- âœ… Full/incremental indexing support
- âœ… File-level indexing and re-indexing
- âœ… Vector search and metadata filtering

**Phase 4** (File Watcher):

- âœ… watchdog-based file system monitoring
- âœ… Debounced file change detection (2-second default)
- âœ… Git commit monitoring with polling
- âœ… Automatic incremental indexing on changes
- âœ… Integration with RAG pipeline API

**Phase 5** (RAG Retrieval):

- âœ… Semantic search with ChromaDB
- âœ… MMR (Maximal Marginal Relevance) reranking
- âœ… Diversity-based reranking algorithms
- âœ… Context assembly for LLM prompts
- âœ… Metadata filtering (language, file, type)
- âœ… Hybrid search (semantic + keyword)
- âœ… Query API endpoint with full retrieval pipeline

**Phase 6** (LLM Integration):

- âœ… Codex CLI provider for ChatGPT Enterprise
- âœ… Ollama provider for offline usage
- âœ… LLM factory pattern with auto-configuration
- âœ… Streaming response support
- âœ… Error handling and fallbacks
- âœ… Query endpoint with LLM generation
- âœ… Chat-based and prompt-based APIs

**Phase 7** (Web UI with Gradio):

- âœ… Gradio-based web interface
- âœ… Chat interface with message history and code syntax highlighting
- âœ… Repository directory picker with real-time Git validation
- âœ… Repository management panel (add/switch repos)
- âœ… Indexing status display
- âœ… Settings and help documentation
- âœ… Dockerized web-ui service

### ðŸ“… Next Steps: Phase 8

**Phase 8** (Testing & Polish):

- Unit tests for critical components
- Integration tests for end-to-end flow
- Performance optimization
- Documentation improvements

See the [implementation plan](.claude/plans/golden-popping-iverson.md) for full details.

## Quick Start

```bash
# 1. Install Codex CLI and authenticate with ChatGPT Enterprise
codex auth login

# 2. Copy environment file
cp .env.example .env

# 3. Start services
docker-compose up --build

# 4. Access the UI
open http://localhost:7860
```

## Documentation

For full setup instructions, architecture details, and API documentation, see:

- [Implementation Plan](.claude/plans/golden-popping-iverson.md)
- API Docs: <http://localhost:8001/docs> (when running)

## Technology Stack

- **Vector DB**: ChromaDB
- **Embedding**: sentence-transformers
- **LLM**: Codex CLI (ChatGPT Enterprise)
- **API**: FastAPI + Python 3.11
- **UI**: Gradio (Phase 7)

---

**Current Status**: Phase 1 & 2 Complete | Ready for Phase 3 (Embedding & Vector Store)
